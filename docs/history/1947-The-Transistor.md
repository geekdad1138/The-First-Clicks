## **Bardeen, Brattain, & Shockley: The Transistor (1947)**

### **What problem existed?**

In the 1940s, computers like ENIAC were literal "room-fillers" that relied on **vacuum tubes**. These tubes were essentially glass lightbulbs: they were fragile, generated massive amounts of heat, and burned out constantly (forcing engineers to hunt down the dead bulb in a maze of wiring). Most importantly, they were slow and impossible to shrink. If we had stayed with vacuum tubes, a modern smartphone would have to be the size of a city block and would require a dedicated power plant to run.

### **What did this person actually do?**

Working at Bell Labs, John Bardeen, Walter Brattain, and William Shockley developed the first "point-contact" transistor using germanium. It was a solid-state device that could act as both an amplifier and—crucially for computing—a **switch**. Unlike the vacuum tube, it had no moving parts, no glass to break, and no filament to burn out.

### **Why did it unlock something?**

It allowed us to manipulate electricity with **semiconductors**. This meant we could flip a switch (a "0" to a "1") millions, then billions, of times per second without anything wearing out. It turned the "Universal Turing Machine" from a slow, mechanical concept into a lightning-fast electronic reality. It also allowed for **miniaturization**: because transistors are made of solid materials, we could eventually learn to etch thousands, and then billions, of them onto a single sliver of silicon.

### **What wouldn't exist without it?**

* **Moore’s Law:** The exponential growth of computing power—the very thing that makes "Training" an AI possible—is entirely a story of making transistors smaller and cheaper.
* **The Integrated Circuit:** Without the individual transistor, we never would have reached the "Microchip," which is just a massive city of transistors living on a chip.
* **Modern AI Hardware:** GPUs and TPUs (Tensor Processing Units) are effectively just highly specialized arrays of billions of transistors designed to perform the math for backpropagation at the speed of light.

---

**Would you like to head to the 1950s next to see the Dartmouth Workshop (where the term "AI" was born), or perhaps look at the "Perceptron" (1958) to see the very first physical attempt at a neural network?**